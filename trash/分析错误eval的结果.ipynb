{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import dotenv\n",
    "from tqdm import tqdm\n",
    "dotenv.load_dotenv()\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def aggregate_scores(eval_dir):    \n",
    "    scores = []\n",
    "    for file in tqdm(os.listdir(eval_dir)):\n",
    "        if file.endswith(\".pkl\"):\n",
    "            with open(os.path.join(eval_dir, file), \"rb\") as f:\n",
    "                result = pickle.load(f)\n",
    "            scores.extend(result['qwen_scores'])\n",
    "    return scores\n",
    "\n",
    "# eval_dir = \"/home/song/code/frag4/output/train/evaluation/Qwen/Qwen2.5-7B-Instruct/squad/greedy_golden\"\n",
    "# scores = aggregate_scores(eval_dir)\n",
    "# print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Qwen/Qwen2.5-7B-Instruct greedy_golden mean std\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 31109.94it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 41213.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Qwen/Qwen2.5-7B-Instruct greedy_without mean std\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 50776.96it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 57578.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Qwen/Qwen2.5-7B-Instruct greedy_irrelevant mean std\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 62418.95it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 61579.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train meta-llama/Llama-3.1-8B-Instruct greedy_golden mean std\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 64603.79it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 65037.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train meta-llama/Llama-3.1-8B-Instruct greedy_without mean std\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 62779.11it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 63764.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train meta-llama/Llama-3.1-8B-Instruct greedy_irrelevant mean std\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 63766.96it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 63711.75it/s]\n"
     ]
    }
   ],
   "source": [
    "datasets=[\"squad\", \"triviaqa\"]\n",
    "models=[\"Qwen/Qwen2.5-7B-Instruct\", \"meta-llama/Llama-3.1-8B-Instruct\"]\n",
    "samples=[\"greedy_golden\", \"greedy_without\", \"greedy_irrelevant\"]\n",
    "# splits=[\"train\", \"test\", \"validation\"]\n",
    "splits=[\"train\"]\n",
    "\n",
    "all_scores = defaultdict(dict)\n",
    "for split in splits:\n",
    "    for model in models:\n",
    "        for sample in samples:\n",
    "            print(f\"{split} {model} {sample} mean std\")\n",
    "            for dataset in datasets:\n",
    "                eval_dir = f\"/home/song/code/frag4/output/{split}/evaluation/{model}/{dataset}/{sample}\"\n",
    "                scores = aggregate_scores(eval_dir)\n",
    "                assert all(x in [0, 1] for x in scores)\n",
    "                all_scores[f\"{split}-{model}-{sample}\"][dataset] = f\"{np.mean(scores):.2f}\"\n",
    "import json\n",
    "json.dump(all_scores, open(\"all_scores.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"all_scores.json\" looks like this:\n",
    "{\n",
    "    \"train-Qwen/Qwen2.5-7B-Instruct-greedy_golden\": {\n",
    "        \"squad\": \"0.88\",\n",
    "        \"triviaqa\": \"0.82\"\n",
    "    },\n",
    "    \"train-Qwen/Qwen2.5-7B-Instruct-greedy_without\": {\n",
    "        \"squad\": \"0.26\",\n",
    "        \"triviaqa\": \"0.62\"\n",
    "    },\n",
    "    \"train-Qwen/Qwen2.5-7B-Instruct-greedy_irrelevant\": {\n",
    "        \"squad\": \"0.11\",\n",
    "        \"triviaqa\": \"0.42\"\n",
    "    },\n",
    "    \"train-meta-llama/Llama-3.1-8B-Instruct-greedy_golden\": {\n",
    "        \"squad\": \"0.76\",\n",
    "        \"triviaqa\": \"0.69\"\n",
    "    },\n",
    "    \"train-meta-llama/Llama-3.1-8B-Instruct-greedy_without\": {\n",
    "        \"squad\": \"0.28\",\n",
    "        \"triviaqa\": \"0.74\"\n",
    "    },\n",
    "    \"train-meta-llama/Llama-3.1-8B-Instruct-greedy_irrelevant\": {\n",
    "        \"squad\": \"0.24\",\n",
    "        \"triviaqa\": \"0.60\"\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
